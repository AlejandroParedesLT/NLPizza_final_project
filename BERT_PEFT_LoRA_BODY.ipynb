{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT with LoRA for analysis on political leaning of news; BODY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwAV24NJ-ZSj",
    "outputId": "f707f622-fcd8-4645-fc3f-6beaef291c8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/miniconda3/lib/python3.12/site-packages (4.46.3)\n",
      "Requirement already satisfied: datasets in /opt/miniconda3/lib/python3.12/site-packages (3.1.0)\n",
      "Requirement already satisfied: peft in /opt/miniconda3/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: evaluate in /opt/miniconda3/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ilseoplee/.local/lib/python3.12/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (3.11.0)\n",
      "Requirement already satisfied: psutil in /opt/miniconda3/lib/python3.12/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/miniconda3/lib/python3.12/site-packages (from peft) (2.5.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/miniconda3/lib/python3.12/site-packages (from peft) (1.1.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (75.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets peft evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "C2gg1Syx-s44"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "KfUh_vrS_hbR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "\n",
    "# Define label maps\n",
    "id2label = {0: \"UNDEFINED\", 1: \"LEFT\", 2: \"RIGHT\", 3: \"CENTER\"}\n",
    "label2id = {\"UNDEFINED\": 0, \"LEFT\": 1, \"RIGHT\": 2, \"CENTER\": 3}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=4, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "Yrj-hSULAi_a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning'],\n",
       "        num_rows: 146718\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "df = load_dataset(\"csv\", data_files=\"/Users/ilseoplee/NLPizza_final_project/Filing/LORA_Head/2017_1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_testvalid =\n",
    "df = df[\"train\"].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "vKd0MpK9BFPv"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "ERySJZcQBp9_"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    text = examples[\"body\"]\n",
    "    labels = examples[\"political_leaning\"]\n",
    "\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text, return_tensors=\"np\", padding=True, truncation=True, max_length=512\n",
    "    )\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = [label2id[label] for label in labels]\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "YmGXgdNQCb7e"
   },
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "ZgXdBTYUDLz6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f70c827db3f48d88ecdd953e398b2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14672 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 132046\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14672\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = df.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "IjSOWH6wDNHw"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "KJvaBgtkD963"
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "6nP1LQquEmt2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model\n",
      "It was good. - UNDEFINED\n",
      "Not a fan, don't recommended - UNDEFINED\n",
      "Better than the first one. - UNDEFINED\n",
      "Women have the right to choose and abortion should be allowed. - UNDEFINED\n"
     ]
    }
   ],
   "source": [
    "text_list = [\n",
    "    \"It was good.\",\n",
    "    \"Not a fan, don't recommended\",\n",
    "    \"Better than the first one.\",\n",
    "    \"Women have the right to choose and abortion should be allowed.\",\n",
    "]\n",
    "\n",
    "import torch\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Untrained model\")\n",
    "for text in text_list:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(\n",
    "        device\n",
    "    )  # Move inputs to the correct device\n",
    "    logits = model(**inputs).logits  # Forward pass\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    print(f\"{text} - {id2label[predictions.item()]}\")\n",
    "\n",
    "# print(\"Untrained model\")\n",
    "# for text in text_list:\n",
    "#   inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "#   logits = model(inputs).logits\n",
    "#   predictions = torch.argmax(logits)\n",
    "#   print(f'{text} - {id2label[predictions.tolist()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "8xiaVnUaF1Yf"
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\", r=4, lora_alpha=32, lora_dropout=0.01, target_modules=[\"q_lin\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "o4hduUwTGnN5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 630,532 || all params: 67,587,080 || trainable%: 0.9329\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3ORBVjXnGx19"
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 10\n",
    "num_epochs = 5\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"\" + model_checkpoint + \"lora-txt\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):  #Training\n",
    "    \"\"\"\n",
    "    Computes accuracy, precision, recall, and F1 score.\n",
    "    eval_pred: A tuple of (predictions, labels) provided by the Trainer.\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    # Convert predictions to the predicted class indices (argmax for softmax outputs)\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions, average='weighted')  # Weighted for class imbalance\n",
    "    recall = recall_score(labels, predictions, average='weighted')\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "hmS4TS65IDDV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/gkxw33gj58n2ptpf02t8_ncr0000gn/T/ipykernel_94675/552906714.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "gfzk-YnMJL0V"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3633e14a3d104d9e92f9a86209a71dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8287, 'grad_norm': 4.748694896697998, 'learning_rate': 0.0009924271109428247, 'epoch': 0.04}\n",
      "{'loss': 0.6316, 'grad_norm': 9.43201732635498, 'learning_rate': 0.0009848542218856495, 'epoch': 0.08}\n",
      "{'loss': 0.6149, 'grad_norm': 3.449251413345337, 'learning_rate': 0.0009772813328284742, 'epoch': 0.11}\n",
      "{'loss': 0.5521, 'grad_norm': 6.571860313415527, 'learning_rate': 0.0009697084437712988, 'epoch': 0.15}\n",
      "{'loss': 0.5324, 'grad_norm': 6.062027931213379, 'learning_rate': 0.0009621355547141235, 'epoch': 0.19}\n",
      "{'loss': 0.5253, 'grad_norm': 9.735512733459473, 'learning_rate': 0.0009545626656569481, 'epoch': 0.23}\n",
      "{'loss': 0.5188, 'grad_norm': 21.42173194885254, 'learning_rate': 0.0009469897765997728, 'epoch': 0.27}\n",
      "{'loss': 0.5011, 'grad_norm': 10.18978500366211, 'learning_rate': 0.0009394168875425976, 'epoch': 0.3}\n",
      "{'loss': 0.4707, 'grad_norm': 6.81619119644165, 'learning_rate': 0.0009318439984854222, 'epoch': 0.34}\n",
      "{'loss': 0.4687, 'grad_norm': 13.150165557861328, 'learning_rate': 0.0009242711094282469, 'epoch': 0.38}\n",
      "{'loss': 0.4508, 'grad_norm': 3.7405965328216553, 'learning_rate': 0.0009166982203710715, 'epoch': 0.42}\n",
      "{'loss': 0.4599, 'grad_norm': 3.0189926624298096, 'learning_rate': 0.0009091253313138963, 'epoch': 0.45}\n",
      "{'loss': 0.4244, 'grad_norm': 7.353954315185547, 'learning_rate': 0.000901552442256721, 'epoch': 0.49}\n",
      "{'loss': 0.4701, 'grad_norm': 4.838909149169922, 'learning_rate': 0.0008939795531995456, 'epoch': 0.53}\n",
      "{'loss': 0.4463, 'grad_norm': 6.230142116546631, 'learning_rate': 0.0008864066641423704, 'epoch': 0.57}\n",
      "{'loss': 0.4476, 'grad_norm': 24.957134246826172, 'learning_rate': 0.000878833775085195, 'epoch': 0.61}\n",
      "{'loss': 0.4403, 'grad_norm': 27.58493423461914, 'learning_rate': 0.0008712608860280196, 'epoch': 0.64}\n",
      "{'loss': 0.4631, 'grad_norm': 3.05045485496521, 'learning_rate': 0.0008636879969708444, 'epoch': 0.68}\n",
      "{'loss': 0.4626, 'grad_norm': 8.103437423706055, 'learning_rate': 0.0008561151079136691, 'epoch': 0.72}\n",
      "{'loss': 0.4593, 'grad_norm': 3.425828456878662, 'learning_rate': 0.0008485422188564938, 'epoch': 0.76}\n",
      "{'loss': 0.4556, 'grad_norm': 7.697094917297363, 'learning_rate': 0.0008409693297993185, 'epoch': 0.8}\n",
      "{'loss': 0.4477, 'grad_norm': 8.24532699584961, 'learning_rate': 0.0008333964407421431, 'epoch': 0.83}\n",
      "{'loss': 0.4507, 'grad_norm': 15.42550277709961, 'learning_rate': 0.0008258235516849678, 'epoch': 0.87}\n",
      "{'loss': 0.448, 'grad_norm': 6.584781169891357, 'learning_rate': 0.0008182506626277926, 'epoch': 0.91}\n",
      "{'loss': 0.4306, 'grad_norm': 16.820331573486328, 'learning_rate': 0.0008106777735706173, 'epoch': 0.95}\n",
      "{'loss': 0.416, 'grad_norm': 12.168789863586426, 'learning_rate': 0.0008031048845134419, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4602805fea8f4d4886b85ec63719fb66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3901447653770447, 'eval_accuracy': 0.8636859323882224, 'eval_precision': 0.8651431915030486, 'eval_recall': 0.8636859323882224, 'eval_f1': 0.862021879021791, 'eval_runtime': 206.6558, 'eval_samples_per_second': 70.997, 'eval_steps_per_second': 7.104, 'epoch': 1.0}\n",
      "{'loss': 0.4254, 'grad_norm': 14.58061408996582, 'learning_rate': 0.0007955319954562665, 'epoch': 1.02}\n",
      "{'loss': 0.4492, 'grad_norm': 14.51124382019043, 'learning_rate': 0.0007879591063990913, 'epoch': 1.06}\n",
      "{'loss': 0.4416, 'grad_norm': 11.60539436340332, 'learning_rate': 0.0007803862173419159, 'epoch': 1.1}\n",
      "{'loss': 0.4482, 'grad_norm': 2.033473014831543, 'learning_rate': 0.0007728133282847406, 'epoch': 1.14}\n",
      "{'loss': 0.4298, 'grad_norm': 4.922005653381348, 'learning_rate': 0.0007652404392275654, 'epoch': 1.17}\n",
      "{'loss': 0.4118, 'grad_norm': 44.417884826660156, 'learning_rate': 0.00075766755017039, 'epoch': 1.21}\n",
      "{'loss': 0.4164, 'grad_norm': 21.770553588867188, 'learning_rate': 0.0007500946611132147, 'epoch': 1.25}\n",
      "{'loss': 0.4187, 'grad_norm': 12.923595428466797, 'learning_rate': 0.0007425217720560394, 'epoch': 1.29}\n",
      "{'loss': 0.4081, 'grad_norm': 2.9803476333618164, 'learning_rate': 0.000734948882998864, 'epoch': 1.33}\n",
      "{'loss': 0.4249, 'grad_norm': 4.583873271942139, 'learning_rate': 0.0007273759939416888, 'epoch': 1.36}\n",
      "{'loss': 0.425, 'grad_norm': 26.126855850219727, 'learning_rate': 0.0007198031048845135, 'epoch': 1.4}\n",
      "{'loss': 0.4128, 'grad_norm': 11.046480178833008, 'learning_rate': 0.0007122302158273382, 'epoch': 1.44}\n",
      "{'loss': 0.4083, 'grad_norm': 4.571284294128418, 'learning_rate': 0.0007046573267701628, 'epoch': 1.48}\n",
      "{'loss': 0.4101, 'grad_norm': 20.389184951782227, 'learning_rate': 0.0006970844377129875, 'epoch': 1.51}\n",
      "{'loss': 0.4068, 'grad_norm': 8.468223571777344, 'learning_rate': 0.0006895115486558123, 'epoch': 1.55}\n",
      "{'loss': 0.4113, 'grad_norm': 6.933456897735596, 'learning_rate': 0.0006819386595986369, 'epoch': 1.59}\n",
      "{'loss': 0.416, 'grad_norm': 4.4070611000061035, 'learning_rate': 0.0006743657705414615, 'epoch': 1.63}\n",
      "{'loss': 0.3917, 'grad_norm': 13.556402206420898, 'learning_rate': 0.0006667928814842863, 'epoch': 1.67}\n",
      "{'loss': 0.4196, 'grad_norm': 4.038666725158691, 'learning_rate': 0.0006592199924271109, 'epoch': 1.7}\n",
      "{'loss': 0.3908, 'grad_norm': 14.946023941040039, 'learning_rate': 0.0006516471033699356, 'epoch': 1.74}\n",
      "{'loss': 0.3942, 'grad_norm': 7.668233871459961, 'learning_rate': 0.0006440742143127604, 'epoch': 1.78}\n",
      "{'loss': 0.3981, 'grad_norm': 19.824277877807617, 'learning_rate': 0.000636501325255585, 'epoch': 1.82}\n",
      "{'loss': 0.3863, 'grad_norm': 3.3519115447998047, 'learning_rate': 0.0006289284361984097, 'epoch': 1.86}\n",
      "{'loss': 0.4091, 'grad_norm': 7.925019264221191, 'learning_rate': 0.0006213555471412344, 'epoch': 1.89}\n",
      "{'loss': 0.412, 'grad_norm': 10.277767181396484, 'learning_rate': 0.000613782658084059, 'epoch': 1.93}\n",
      "{'loss': 0.3811, 'grad_norm': 15.834887504577637, 'learning_rate': 0.0006062097690268838, 'epoch': 1.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc89c5efa2b44fe499e3876744e80cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3659074902534485, 'eval_accuracy': 0.8736368593238822, 'eval_precision': 0.8736656151536688, 'eval_recall': 0.8736368593238822, 'eval_f1': 0.8734697771736488, 'eval_runtime': 183.3657, 'eval_samples_per_second': 80.015, 'eval_steps_per_second': 8.006, 'epoch': 2.0}\n",
      "{'loss': 0.3962, 'grad_norm': 2.1413371562957764, 'learning_rate': 0.0005986368799697085, 'epoch': 2.01}\n",
      "{'loss': 0.3686, 'grad_norm': 6.581758499145508, 'learning_rate': 0.0005910639909125332, 'epoch': 2.04}\n",
      "{'loss': 0.3896, 'grad_norm': 12.2778902053833, 'learning_rate': 0.0005834911018553578, 'epoch': 2.08}\n",
      "{'loss': 0.3777, 'grad_norm': 37.872291564941406, 'learning_rate': 0.0005759182127981825, 'epoch': 2.12}\n",
      "{'loss': 0.3708, 'grad_norm': 3.4691784381866455, 'learning_rate': 0.0005683453237410072, 'epoch': 2.16}\n",
      "{'loss': 0.3976, 'grad_norm': 5.366386413574219, 'learning_rate': 0.0005607724346838319, 'epoch': 2.2}\n",
      "{'loss': 0.4009, 'grad_norm': 3.442211389541626, 'learning_rate': 0.0005531995456266566, 'epoch': 2.23}\n",
      "{'loss': 0.3847, 'grad_norm': 10.476218223571777, 'learning_rate': 0.0005456266565694813, 'epoch': 2.27}\n",
      "{'loss': 0.4077, 'grad_norm': 32.96021270751953, 'learning_rate': 0.0005380537675123059, 'epoch': 2.31}\n",
      "{'loss': 0.3686, 'grad_norm': 12.468318939208984, 'learning_rate': 0.0005304808784551306, 'epoch': 2.35}\n",
      "{'loss': 0.4075, 'grad_norm': 0.4845803380012512, 'learning_rate': 0.0005229079893979554, 'epoch': 2.39}\n",
      "{'loss': 0.3714, 'grad_norm': 12.69819164276123, 'learning_rate': 0.00051533510034078, 'epoch': 2.42}\n",
      "{'loss': 0.3956, 'grad_norm': 29.154775619506836, 'learning_rate': 0.0005077622112836047, 'epoch': 2.46}\n",
      "{'loss': 0.3708, 'grad_norm': 26.169788360595703, 'learning_rate': 0.0005001893222264294, 'epoch': 2.5}\n",
      "{'loss': 0.4035, 'grad_norm': 3.5239014625549316, 'learning_rate': 0.0004926164331692541, 'epoch': 2.54}\n",
      "{'loss': 0.4112, 'grad_norm': 24.178613662719727, 'learning_rate': 0.0004850435441120788, 'epoch': 2.57}\n",
      "{'loss': 0.3741, 'grad_norm': 7.900997638702393, 'learning_rate': 0.00047747065505490346, 'epoch': 2.61}\n",
      "{'loss': 0.369, 'grad_norm': 8.318049430847168, 'learning_rate': 0.00046989776599772813, 'epoch': 2.65}\n",
      "{'loss': 0.3844, 'grad_norm': 16.4931583404541, 'learning_rate': 0.0004623248769405528, 'epoch': 2.69}\n",
      "{'loss': 0.3747, 'grad_norm': 8.846147537231445, 'learning_rate': 0.0004547519878833775, 'epoch': 2.73}\n",
      "{'loss': 0.3614, 'grad_norm': 2.888808250427246, 'learning_rate': 0.00044717909882620224, 'epoch': 2.76}\n",
      "{'loss': 0.3481, 'grad_norm': 0.7002111077308655, 'learning_rate': 0.0004396062097690269, 'epoch': 2.8}\n",
      "{'loss': 0.3622, 'grad_norm': 17.268129348754883, 'learning_rate': 0.00043203332071185157, 'epoch': 2.84}\n",
      "{'loss': 0.3571, 'grad_norm': 12.067517280578613, 'learning_rate': 0.0004244604316546763, 'epoch': 2.88}\n",
      "{'loss': 0.3622, 'grad_norm': 3.7851014137268066, 'learning_rate': 0.00041688754259750096, 'epoch': 2.92}\n",
      "{'loss': 0.372, 'grad_norm': 5.940782070159912, 'learning_rate': 0.0004093146535403257, 'epoch': 2.95}\n",
      "{'loss': 0.3736, 'grad_norm': 4.131073951721191, 'learning_rate': 0.0004017417644831503, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c944953199f4b7b993655714bfe0bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3323524594306946, 'eval_accuracy': 0.8880179934569248, 'eval_precision': 0.8884314537818313, 'eval_recall': 0.8880179934569248, 'eval_f1': 0.8871161729000467, 'eval_runtime': 181.3339, 'eval_samples_per_second': 80.912, 'eval_steps_per_second': 8.096, 'epoch': 3.0}\n",
      "{'loss': 0.3462, 'grad_norm': 11.210787773132324, 'learning_rate': 0.000394168875425975, 'epoch': 3.03}\n",
      "{'loss': 0.3438, 'grad_norm': 17.527494430541992, 'learning_rate': 0.00038659598636879973, 'epoch': 3.07}\n",
      "{'loss': 0.3471, 'grad_norm': 16.668025970458984, 'learning_rate': 0.0003790230973116244, 'epoch': 3.1}\n",
      "{'loss': 0.3485, 'grad_norm': 7.274332046508789, 'learning_rate': 0.00037145020825444906, 'epoch': 3.14}\n",
      "{'loss': 0.3388, 'grad_norm': 1.66489577293396, 'learning_rate': 0.0003638773191972738, 'epoch': 3.18}\n",
      "{'loss': 0.359, 'grad_norm': 1.5970563888549805, 'learning_rate': 0.00035630443014009845, 'epoch': 3.22}\n",
      "{'loss': 0.3263, 'grad_norm': 7.26780891418457, 'learning_rate': 0.00034873154108292317, 'epoch': 3.26}\n",
      "{'loss': 0.3409, 'grad_norm': 7.8111748695373535, 'learning_rate': 0.0003411586520257478, 'epoch': 3.29}\n",
      "{'loss': 0.3326, 'grad_norm': 1.0981147289276123, 'learning_rate': 0.0003335857629685725, 'epoch': 3.33}\n",
      "{'loss': 0.3316, 'grad_norm': 7.220420837402344, 'learning_rate': 0.0003260128739113972, 'epoch': 3.37}\n",
      "{'loss': 0.3374, 'grad_norm': 10.83053970336914, 'learning_rate': 0.0003184399848542219, 'epoch': 3.41}\n",
      "{'loss': 0.33, 'grad_norm': 8.083961486816406, 'learning_rate': 0.0003108670957970466, 'epoch': 3.45}\n",
      "{'loss': 0.3113, 'grad_norm': 0.26601478457450867, 'learning_rate': 0.0003032942067398713, 'epoch': 3.48}\n",
      "{'loss': 0.3174, 'grad_norm': 10.832043647766113, 'learning_rate': 0.00029572131768269594, 'epoch': 3.52}\n",
      "{'loss': 0.3342, 'grad_norm': 21.377885818481445, 'learning_rate': 0.00028814842862552066, 'epoch': 3.56}\n",
      "{'loss': 0.305, 'grad_norm': 1.3034964799880981, 'learning_rate': 0.00028057553956834533, 'epoch': 3.6}\n",
      "{'loss': 0.3144, 'grad_norm': 3.993391513824463, 'learning_rate': 0.00027300265051117, 'epoch': 3.63}\n",
      "{'loss': 0.3451, 'grad_norm': 14.902138710021973, 'learning_rate': 0.0002654297614539947, 'epoch': 3.67}\n",
      "{'loss': 0.3269, 'grad_norm': 5.959630489349365, 'learning_rate': 0.0002578568723968194, 'epoch': 3.71}\n",
      "{'loss': 0.3215, 'grad_norm': 3.7636220455169678, 'learning_rate': 0.0002502839833396441, 'epoch': 3.75}\n",
      "{'loss': 0.3201, 'grad_norm': 0.43561026453971863, 'learning_rate': 0.00024271109428246877, 'epoch': 3.79}\n",
      "{'loss': 0.3334, 'grad_norm': 7.331313133239746, 'learning_rate': 0.00023513820522529344, 'epoch': 3.82}\n",
      "{'loss': 0.3117, 'grad_norm': 3.3008134365081787, 'learning_rate': 0.00022756531616811816, 'epoch': 3.86}\n",
      "{'loss': 0.3183, 'grad_norm': 4.461067199707031, 'learning_rate': 0.00021999242711094282, 'epoch': 3.9}\n",
      "{'loss': 0.3008, 'grad_norm': 32.658355712890625, 'learning_rate': 0.00021241953805376752, 'epoch': 3.94}\n",
      "{'loss': 0.2879, 'grad_norm': 5.598228454589844, 'learning_rate': 0.00020484664899659218, 'epoch': 3.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33653d1ba7144cda053ae02d32df3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3035416007041931, 'eval_accuracy': 0.9017175572519084, 'eval_precision': 0.9022964681872638, 'eval_recall': 0.9017175572519084, 'eval_f1': 0.9005797837820249, 'eval_runtime': 180.471, 'eval_samples_per_second': 81.298, 'eval_steps_per_second': 8.134, 'epoch': 4.0}\n",
      "{'loss': 0.3046, 'grad_norm': 2.8429315090179443, 'learning_rate': 0.0001972737599394169, 'epoch': 4.01}\n",
      "{'loss': 0.2904, 'grad_norm': 1.144376516342163, 'learning_rate': 0.0001897008708822416, 'epoch': 4.05}\n",
      "{'loss': 0.3082, 'grad_norm': 3.105647087097168, 'learning_rate': 0.00018212798182506626, 'epoch': 4.09}\n",
      "{'loss': 0.283, 'grad_norm': 110.03023529052734, 'learning_rate': 0.00017455509276789096, 'epoch': 4.13}\n",
      "{'loss': 0.2631, 'grad_norm': 2.8784265518188477, 'learning_rate': 0.00016698220371071565, 'epoch': 4.17}\n",
      "{'loss': 0.2825, 'grad_norm': 11.242555618286133, 'learning_rate': 0.00015940931465354034, 'epoch': 4.2}\n",
      "{'loss': 0.2695, 'grad_norm': 4.8011016845703125, 'learning_rate': 0.000151836425596365, 'epoch': 4.24}\n",
      "{'loss': 0.2801, 'grad_norm': 8.945869445800781, 'learning_rate': 0.0001442635365391897, 'epoch': 4.28}\n",
      "{'loss': 0.2936, 'grad_norm': 4.880528926849365, 'learning_rate': 0.0001366906474820144, 'epoch': 4.32}\n",
      "{'loss': 0.2826, 'grad_norm': 2.3446059226989746, 'learning_rate': 0.0001291177584248391, 'epoch': 4.35}\n",
      "{'loss': 0.2959, 'grad_norm': 5.659092903137207, 'learning_rate': 0.00012154486936766377, 'epoch': 4.39}\n",
      "{'loss': 0.2936, 'grad_norm': 6.816344738006592, 'learning_rate': 0.00011397198031048846, 'epoch': 4.43}\n",
      "{'loss': 0.2733, 'grad_norm': 1.5820932388305664, 'learning_rate': 0.00010639909125331314, 'epoch': 4.47}\n",
      "{'loss': 0.2857, 'grad_norm': 5.22636604309082, 'learning_rate': 9.882620219613784e-05, 'epoch': 4.51}\n",
      "{'loss': 0.2739, 'grad_norm': 7.239253997802734, 'learning_rate': 9.125331313896252e-05, 'epoch': 4.54}\n",
      "{'loss': 0.2861, 'grad_norm': 15.581671714782715, 'learning_rate': 8.368042408178721e-05, 'epoch': 4.58}\n",
      "{'loss': 0.2841, 'grad_norm': 7.939411640167236, 'learning_rate': 7.610753502461189e-05, 'epoch': 4.62}\n",
      "{'loss': 0.2675, 'grad_norm': 8.069210052490234, 'learning_rate': 6.853464596743658e-05, 'epoch': 4.66}\n",
      "{'loss': 0.2747, 'grad_norm': 6.22581148147583, 'learning_rate': 6.096175691026127e-05, 'epoch': 4.7}\n",
      "{'loss': 0.2776, 'grad_norm': 5.284555435180664, 'learning_rate': 5.3388867853085956e-05, 'epoch': 4.73}\n",
      "{'loss': 0.2604, 'grad_norm': 1.8149378299713135, 'learning_rate': 4.581597879591064e-05, 'epoch': 4.77}\n",
      "{'loss': 0.2869, 'grad_norm': 3.893207550048828, 'learning_rate': 3.824308973873533e-05, 'epoch': 4.81}\n",
      "{'loss': 0.2603, 'grad_norm': 10.23295783996582, 'learning_rate': 3.0670200681560016e-05, 'epoch': 4.85}\n",
      "{'loss': 0.2858, 'grad_norm': 0.6673018932342529, 'learning_rate': 2.3097311624384703e-05, 'epoch': 4.88}\n",
      "{'loss': 0.2869, 'grad_norm': 5.940642356872559, 'learning_rate': 1.552442256720939e-05, 'epoch': 4.92}\n",
      "{'loss': 0.2884, 'grad_norm': 3.2069883346557617, 'learning_rate': 7.951533510034078e-06, 'epoch': 4.96}\n",
      "{'loss': 0.2653, 'grad_norm': 17.67391014099121, 'learning_rate': 3.786444528587656e-07, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e7092f562844bba3b33aa7be3e6bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28180262446403503, 'eval_accuracy': 0.9074427480916031, 'eval_precision': 0.908375419554778, 'eval_recall': 0.9074427480916031, 'eval_f1': 0.9066165564820392, 'eval_runtime': 182.4428, 'eval_samples_per_second': 80.42, 'eval_steps_per_second': 8.046, 'epoch': 5.0}\n",
      "{'train_runtime': 18599.8932, 'train_samples_per_second': 35.496, 'train_steps_per_second': 3.55, 'train_loss': 0.3784656818018678, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=66025, training_loss=0.3784656818018678, metrics={'train_runtime': 18599.8932, 'train_samples_per_second': 35.496, 'train_steps_per_second': 3.55, 'total_flos': 8.874093177643008e+16, 'train_loss': 0.3784656818018678, 'epoch': 5.0})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "0jn1iHMyJNtM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Trained model predictions\n",
      "It was good. - UNDEFINED\n",
      "Not a fan, don't recommended - UNDEFINED\n",
      "Better than the first one. - UNDEFINED\n",
      "Women have the right to choose and abortion should be allowed. - LEFT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = model.to(device)\n",
    "print(\"Trained model predictions\")\n",
    "\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    logits = model(inputs).logits\n",
    "\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    print(f\"{text} - {id2label[predictions.item()]}\")\n",
    "\n",
    "\n",
    "# INITIAL CODE\n",
    "# model.to('cuda')\n",
    "# print('Trained model predictions')\n",
    "# for text in text_list:\n",
    "#   inputs = tokenizer.encode(text, return_tensors='pt').to('cuda')\n",
    "\n",
    "#   logits = model(inputs).logits\n",
    "#   predictions = torch.max(logits,1).indices\n",
    "\n",
    "#   print(f'{text} - {id2label[predictions.tolist()[0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQ9UjA-nLGzS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files saved\n"
     ]
    }
   ],
   "source": [
    "output_model_file = \"pytorch_distilbert_imbd.bin\"\n",
    "output_vocab_file = \"vocab_distilbert_imbd.bin\"\n",
    "\n",
    "# Save model\n",
    "model_to_save = model\n",
    "torch.save(model_to_save, output_model_file)\n",
    "\n",
    "# Save tokenizer vocabulary in the current directory\n",
    "tokenizer.save_vocabulary(\".\")  # Current directory\n",
    "\n",
    "# Save model state dictionary\n",
    "torch.save(model.state_dict(), \"trained_model_gral_imbd_body_2017_1_shawn\")\n",
    "\n",
    "print(\"All files saved\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
