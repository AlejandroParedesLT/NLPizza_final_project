{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Political leaning analysis by DistilBERT parameter tuning via LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwAV24NJ-ZSj",
    "outputId": "f707f622-fcd8-4645-fc3f-6beaef291c8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/miniconda3/lib/python3.12/site-packages (4.46.3)\n",
      "Requirement already satisfied: datasets in /opt/miniconda3/lib/python3.12/site-packages (3.1.0)\n",
      "Requirement already satisfied: peft in /opt/miniconda3/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: evaluate in /opt/miniconda3/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ilseoplee/.local/lib/python3.12/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (3.11.0)\n",
      "Requirement already satisfied: psutil in /opt/miniconda3/lib/python3.12/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/miniconda3/lib/python3.12/site-packages (from peft) (2.5.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/miniconda3/lib/python3.12/site-packages (from peft) (1.1.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (75.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets peft evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "C2gg1Syx-s44"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KfUh_vrS_hbR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "\n",
    "# Define label maps\n",
    "id2label = {0: \"UNDEFINED\", 1: \"LEFT\", 2: \"RIGHT\", 3: \"CENTER\"}\n",
    "label2id = {\"UNDEFINED\": 0, \"LEFT\": 1, \"RIGHT\": 2, \"CENTER\": 3}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=4, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Yrj-hSULAi_a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning'],\n",
       "        num_rows: 146718\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "df = load_dataset(\"csv\", data_files=\"/Users/ilseoplee/NLPizza_final_project/2017_1.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_testvalid =\n",
    "df = df[\"train\"].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vKd0MpK9BFPv"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ERySJZcQBp9_"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    text = examples[\"lead\"]\n",
    "    labels = examples[\"political_leaning\"]\n",
    "\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text, return_tensors=\"np\", padding=True, truncation=True, max_length=512\n",
    "    )\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = [label2id[label] for label in labels]\n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YmGXgdNQCb7e"
   },
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ff24ee48e74832b5400b41f5954357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/132046 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eca757657544e9eb4de8b6b19d5ec7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/14672 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data(dataset): #treat None values\n",
    "    dataset = dataset.filter(lambda x: x[\"lead\"] is not None and isinstance(x[\"lead\"], str))\n",
    "    return dataset\n",
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZgXdBTYUDLz6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a41773c16c549ffbca75355b38567e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/114318 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd69e63c0094c6fb13af70d70dd5549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12625 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 114318\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 12625\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = df.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IjSOWH6wDNHw"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KJvaBgtkD963"
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6nP1LQquEmt2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model\n",
      "It was good. - UNDEFINED\n",
      "Not a fan, don't recommended - CENTER\n",
      "Better than the first one. - LEFT\n",
      "Women have the right to choose and abortion should be allowed. - LEFT\n"
     ]
    }
   ],
   "source": [
    "text_list = [\n",
    "    \"It was good.\",\n",
    "    \"Not a fan, don't recommended\",\n",
    "    \"Better than the first one.\",\n",
    "    \"Women have the right to choose and abortion should be allowed.\",\n",
    "]\n",
    "\n",
    "import torch\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Untrained model\")\n",
    "for text in text_list:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(\n",
    "        device\n",
    "    )  # Move inputs to the correct device\n",
    "    logits = model(**inputs).logits  # Forward pass\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    print(f\"{text} - {id2label[predictions.item()]}\")\n",
    "\n",
    "# print(\"Untrained model\")\n",
    "# for text in text_list:\n",
    "#   inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "#   logits = model(inputs).logits\n",
    "#   predictions = torch.argmax(logits)\n",
    "#   print(f'{text} - {id2label[predictions.tolist()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8xiaVnUaF1Yf"
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\", r=4, lora_alpha=32, lora_dropout=0.01, target_modules=[\"q_lin\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "o4hduUwTGnN5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 630,532 || all params: 67,587,080 || trainable%: 0.9329\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "3ORBVjXnGx19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 10\n",
    "num_epochs = 5\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"\" + model_checkpoint + \"lora-txt\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):  #Training\n",
    "    \"\"\"\n",
    "    Computes accuracy, precision, recall, and F1 score.\n",
    "    eval_pred: A tuple of (predictions, labels) provided by the Trainer.\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    # Convert predictions to the predicted class indices (argmax for softmax outputs)\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions, average='weighted')  # Weighted for class imbalance\n",
    "    recall = recall_score(labels, predictions, average='weighted')\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "hmS4TS65IDDV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/gkxw33gj58n2ptpf02t8_ncr0000gn/T/ipykernel_15891/552906714.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "gfzk-YnMJL0V"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2af1d196eef44169159a5a8dd3a525a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9303, 'grad_norm': 4.505564212799072, 'learning_rate': 0.0009912526242127362, 'epoch': 0.04}\n",
      "{'loss': 0.7897, 'grad_norm': 3.0711629390716553, 'learning_rate': 0.0009825052484254723, 'epoch': 0.09}\n",
      "{'loss': 0.7629, 'grad_norm': 3.4180080890655518, 'learning_rate': 0.0009737578726382086, 'epoch': 0.13}\n",
      "{'loss': 0.747, 'grad_norm': 2.914144992828369, 'learning_rate': 0.0009650104968509448, 'epoch': 0.17}\n",
      "{'loss': 0.7477, 'grad_norm': 3.478550910949707, 'learning_rate': 0.000956263121063681, 'epoch': 0.22}\n",
      "{'loss': 0.7469, 'grad_norm': 5.787277698516846, 'learning_rate': 0.0009475157452764171, 'epoch': 0.26}\n",
      "{'loss': 0.7385, 'grad_norm': 3.0911436080932617, 'learning_rate': 0.0009387683694891532, 'epoch': 0.31}\n",
      "{'loss': 0.7319, 'grad_norm': 3.49379825592041, 'learning_rate': 0.0009300209937018894, 'epoch': 0.35}\n",
      "{'loss': 0.7153, 'grad_norm': 2.440849542617798, 'learning_rate': 0.0009212736179146256, 'epoch': 0.39}\n",
      "{'loss': 0.7083, 'grad_norm': 3.048267126083374, 'learning_rate': 0.0009125262421273618, 'epoch': 0.44}\n",
      "{'loss': 0.7169, 'grad_norm': 4.759026050567627, 'learning_rate': 0.000903778866340098, 'epoch': 0.48}\n",
      "{'loss': 0.7283, 'grad_norm': 2.7879130840301514, 'learning_rate': 0.0008950314905528342, 'epoch': 0.52}\n",
      "{'loss': 0.6913, 'grad_norm': 9.526941299438477, 'learning_rate': 0.0008862841147655704, 'epoch': 0.57}\n",
      "{'loss': 0.7201, 'grad_norm': 6.759109020233154, 'learning_rate': 0.0008775367389783065, 'epoch': 0.61}\n",
      "{'loss': 0.7003, 'grad_norm': 4.028451442718506, 'learning_rate': 0.0008687893631910427, 'epoch': 0.66}\n",
      "{'loss': 0.6949, 'grad_norm': 4.75118350982666, 'learning_rate': 0.0008600419874037789, 'epoch': 0.7}\n",
      "{'loss': 0.6965, 'grad_norm': 6.135900497436523, 'learning_rate': 0.0008512946116165151, 'epoch': 0.74}\n",
      "{'loss': 0.6858, 'grad_norm': 5.771069526672363, 'learning_rate': 0.0008425472358292512, 'epoch': 0.79}\n",
      "{'loss': 0.6915, 'grad_norm': 9.575847625732422, 'learning_rate': 0.0008337998600419874, 'epoch': 0.83}\n",
      "{'loss': 0.7051, 'grad_norm': 5.100236892700195, 'learning_rate': 0.0008250524842547236, 'epoch': 0.87}\n",
      "{'loss': 0.6836, 'grad_norm': 2.7741403579711914, 'learning_rate': 0.0008163051084674598, 'epoch': 0.92}\n",
      "{'loss': 0.723, 'grad_norm': 9.94375991821289, 'learning_rate': 0.0008075577326801959, 'epoch': 0.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1260e629454b758e7f4f1406538548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6697376370429993, 'eval_accuracy': 0.7455049504950495, 'eval_precision': 0.7488754292354503, 'eval_recall': 0.7455049504950495, 'eval_f1': 0.7463705486154194, 'eval_runtime': 129.7641, 'eval_samples_per_second': 97.292, 'eval_steps_per_second': 9.733, 'epoch': 1.0}\n",
      "{'loss': 0.6845, 'grad_norm': 3.5698649883270264, 'learning_rate': 0.0007988103568929321, 'epoch': 1.01}\n",
      "{'loss': 0.6769, 'grad_norm': 10.188803672790527, 'learning_rate': 0.0007900629811056683, 'epoch': 1.05}\n",
      "{'loss': 0.6794, 'grad_norm': 5.290374755859375, 'learning_rate': 0.0007813156053184045, 'epoch': 1.09}\n",
      "{'loss': 0.685, 'grad_norm': 2.6466569900512695, 'learning_rate': 0.0007725682295311407, 'epoch': 1.14}\n",
      "{'loss': 0.6594, 'grad_norm': 2.8511807918548584, 'learning_rate': 0.0007638208537438769, 'epoch': 1.18}\n",
      "{'loss': 0.678, 'grad_norm': 4.404359817504883, 'learning_rate': 0.0007550734779566131, 'epoch': 1.22}\n",
      "{'loss': 0.6711, 'grad_norm': 4.073235034942627, 'learning_rate': 0.0007463261021693492, 'epoch': 1.27}\n",
      "{'loss': 0.6958, 'grad_norm': 5.517349720001221, 'learning_rate': 0.0007375787263820854, 'epoch': 1.31}\n",
      "{'loss': 0.6786, 'grad_norm': 3.792689323425293, 'learning_rate': 0.0007288313505948215, 'epoch': 1.36}\n",
      "{'loss': 0.6571, 'grad_norm': 11.913524627685547, 'learning_rate': 0.0007200839748075578, 'epoch': 1.4}\n",
      "{'loss': 0.6797, 'grad_norm': 2.5136468410491943, 'learning_rate': 0.0007113365990202939, 'epoch': 1.44}\n",
      "{'loss': 0.6518, 'grad_norm': 3.2255663871765137, 'learning_rate': 0.0007025892232330301, 'epoch': 1.49}\n",
      "{'loss': 0.6479, 'grad_norm': 4.571509838104248, 'learning_rate': 0.0006938418474457663, 'epoch': 1.53}\n",
      "{'loss': 0.6461, 'grad_norm': 3.233649253845215, 'learning_rate': 0.0006850944716585024, 'epoch': 1.57}\n",
      "{'loss': 0.6774, 'grad_norm': 6.176367282867432, 'learning_rate': 0.0006763470958712387, 'epoch': 1.62}\n",
      "{'loss': 0.6654, 'grad_norm': 8.004419326782227, 'learning_rate': 0.0006675997200839748, 'epoch': 1.66}\n",
      "{'loss': 0.6586, 'grad_norm': 5.301015853881836, 'learning_rate': 0.0006588523442967111, 'epoch': 1.71}\n",
      "{'loss': 0.6581, 'grad_norm': 4.696744441986084, 'learning_rate': 0.0006501049685094472, 'epoch': 1.75}\n",
      "{'loss': 0.6684, 'grad_norm': 12.62233829498291, 'learning_rate': 0.0006413575927221834, 'epoch': 1.79}\n",
      "{'loss': 0.6423, 'grad_norm': 8.714221000671387, 'learning_rate': 0.0006326102169349195, 'epoch': 1.84}\n",
      "{'loss': 0.6359, 'grad_norm': 4.51986837387085, 'learning_rate': 0.0006238628411476556, 'epoch': 1.88}\n",
      "{'loss': 0.6557, 'grad_norm': 3.389810800552368, 'learning_rate': 0.0006151154653603919, 'epoch': 1.92}\n",
      "{'loss': 0.6538, 'grad_norm': 6.979957103729248, 'learning_rate': 0.000606368089573128, 'epoch': 1.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed951d30aa20497eb890706e9b1806b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6217897534370422, 'eval_accuracy': 0.7588118811881188, 'eval_precision': 0.7681203733288533, 'eval_recall': 0.7588118811881188, 'eval_f1': 0.7570002372018653, 'eval_runtime': 199.3867, 'eval_samples_per_second': 63.319, 'eval_steps_per_second': 6.334, 'epoch': 2.0}\n",
      "{'loss': 0.6388, 'grad_norm': 6.76192569732666, 'learning_rate': 0.0005976207137858643, 'epoch': 2.01}\n",
      "{'loss': 0.6192, 'grad_norm': 2.8097987174987793, 'learning_rate': 0.0005888733379986004, 'epoch': 2.06}\n",
      "{'loss': 0.6391, 'grad_norm': 9.754402160644531, 'learning_rate': 0.0005801259622113367, 'epoch': 2.1}\n",
      "{'loss': 0.6286, 'grad_norm': 3.873807668685913, 'learning_rate': 0.0005713785864240728, 'epoch': 2.14}\n",
      "{'loss': 0.62, 'grad_norm': 3.5799458026885986, 'learning_rate': 0.000562631210636809, 'epoch': 2.19}\n",
      "{'loss': 0.627, 'grad_norm': 3.3360211849212646, 'learning_rate': 0.0005538838348495452, 'epoch': 2.23}\n",
      "{'loss': 0.6474, 'grad_norm': 7.667523384094238, 'learning_rate': 0.0005451364590622813, 'epoch': 2.27}\n",
      "{'loss': 0.6298, 'grad_norm': 5.8668437004089355, 'learning_rate': 0.0005363890832750175, 'epoch': 2.32}\n",
      "{'loss': 0.6396, 'grad_norm': 4.734686374664307, 'learning_rate': 0.0005276417074877536, 'epoch': 2.36}\n",
      "{'loss': 0.6122, 'grad_norm': 2.706854820251465, 'learning_rate': 0.0005188943317004899, 'epoch': 2.41}\n",
      "{'loss': 0.6299, 'grad_norm': 5.266129970550537, 'learning_rate': 0.000510146955913226, 'epoch': 2.45}\n",
      "{'loss': 0.6251, 'grad_norm': 7.186893463134766, 'learning_rate': 0.0005013995801259622, 'epoch': 2.49}\n",
      "{'loss': 0.5828, 'grad_norm': 5.110908031463623, 'learning_rate': 0.0004926522043386984, 'epoch': 2.54}\n",
      "{'loss': 0.6155, 'grad_norm': 6.998584270477295, 'learning_rate': 0.0004839048285514346, 'epoch': 2.58}\n",
      "{'loss': 0.625, 'grad_norm': 13.545248031616211, 'learning_rate': 0.00047515745276417075, 'epoch': 2.62}\n",
      "{'loss': 0.6204, 'grad_norm': 21.900375366210938, 'learning_rate': 0.00046641007697690695, 'epoch': 2.67}\n",
      "{'loss': 0.6142, 'grad_norm': 9.707714080810547, 'learning_rate': 0.0004576627011896431, 'epoch': 2.71}\n",
      "{'loss': 0.6133, 'grad_norm': 7.010843753814697, 'learning_rate': 0.0004489153254023793, 'epoch': 2.76}\n",
      "{'loss': 0.6286, 'grad_norm': 3.7625787258148193, 'learning_rate': 0.0004401679496151155, 'epoch': 2.8}\n",
      "{'loss': 0.5973, 'grad_norm': 2.572082281112671, 'learning_rate': 0.0004314205738278517, 'epoch': 2.84}\n",
      "{'loss': 0.6115, 'grad_norm': 9.732803344726562, 'learning_rate': 0.00042267319804058787, 'epoch': 2.89}\n",
      "{'loss': 0.6192, 'grad_norm': 17.990270614624023, 'learning_rate': 0.000413925822253324, 'epoch': 2.93}\n",
      "{'loss': 0.6111, 'grad_norm': 3.408430814743042, 'learning_rate': 0.00040517844646606016, 'epoch': 2.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa59d26e15364f30a5a471b0837cc16a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.578837513923645, 'eval_accuracy': 0.7765544554455446, 'eval_precision': 0.7857904484585567, 'eval_recall': 0.7765544554455446, 'eval_f1': 0.7793301970423513, 'eval_runtime': 128.9481, 'eval_samples_per_second': 97.908, 'eval_steps_per_second': 9.795, 'epoch': 3.0}\n",
      "{'loss': 0.612, 'grad_norm': 5.217955112457275, 'learning_rate': 0.00039643107067879635, 'epoch': 3.02}\n",
      "{'loss': 0.57, 'grad_norm': 6.749016761779785, 'learning_rate': 0.00038768369489153255, 'epoch': 3.06}\n",
      "{'loss': 0.557, 'grad_norm': 2.5166800022125244, 'learning_rate': 0.00037893631910426874, 'epoch': 3.11}\n",
      "{'loss': 0.5807, 'grad_norm': 6.777468204498291, 'learning_rate': 0.00037018894331700494, 'epoch': 3.15}\n",
      "{'loss': 0.5871, 'grad_norm': 4.157129764556885, 'learning_rate': 0.00036144156752974114, 'epoch': 3.19}\n",
      "{'loss': 0.5865, 'grad_norm': 2.075314521789551, 'learning_rate': 0.0003526941917424772, 'epoch': 3.24}\n",
      "{'loss': 0.5877, 'grad_norm': 4.232352256774902, 'learning_rate': 0.0003439468159552134, 'epoch': 3.28}\n",
      "{'loss': 0.5815, 'grad_norm': 6.485240936279297, 'learning_rate': 0.0003351994401679496, 'epoch': 3.32}\n",
      "{'loss': 0.5636, 'grad_norm': 2.727783441543579, 'learning_rate': 0.0003264520643806858, 'epoch': 3.37}\n",
      "{'loss': 0.5777, 'grad_norm': 2.5722904205322266, 'learning_rate': 0.000317704688593422, 'epoch': 3.41}\n",
      "{'loss': 0.5896, 'grad_norm': 7.3149189949035645, 'learning_rate': 0.0003089573128061582, 'epoch': 3.46}\n",
      "{'loss': 0.5691, 'grad_norm': 10.126087188720703, 'learning_rate': 0.00030020993701889435, 'epoch': 3.5}\n",
      "{'loss': 0.592, 'grad_norm': 5.71168327331543, 'learning_rate': 0.0002914625612316305, 'epoch': 3.54}\n",
      "{'loss': 0.5667, 'grad_norm': 4.440967559814453, 'learning_rate': 0.0002827151854443667, 'epoch': 3.59}\n",
      "{'loss': 0.5776, 'grad_norm': 7.409656524658203, 'learning_rate': 0.0002739678096571029, 'epoch': 3.63}\n",
      "{'loss': 0.581, 'grad_norm': 2.1067941188812256, 'learning_rate': 0.0002652204338698391, 'epoch': 3.67}\n",
      "{'loss': 0.5571, 'grad_norm': 3.3153340816497803, 'learning_rate': 0.0002564730580825752, 'epoch': 3.72}\n",
      "{'loss': 0.556, 'grad_norm': 5.711120128631592, 'learning_rate': 0.0002477256822953114, 'epoch': 3.76}\n",
      "{'loss': 0.585, 'grad_norm': 4.293209552764893, 'learning_rate': 0.00023897830650804758, 'epoch': 3.81}\n",
      "{'loss': 0.5646, 'grad_norm': 2.4188146591186523, 'learning_rate': 0.00023023093072078378, 'epoch': 3.85}\n",
      "{'loss': 0.561, 'grad_norm': 1.456776738166809, 'learning_rate': 0.00022148355493351995, 'epoch': 3.89}\n",
      "{'loss': 0.5747, 'grad_norm': 2.0129148960113525, 'learning_rate': 0.00021273617914625612, 'epoch': 3.94}\n",
      "{'loss': 0.5458, 'grad_norm': 7.247500896453857, 'learning_rate': 0.0002039888033589923, 'epoch': 3.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0aa8cc4bbb4a21924e78f7d4246f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5534246563911438, 'eval_accuracy': 0.783920792079208, 'eval_precision': 0.7895896753683193, 'eval_recall': 0.783920792079208, 'eval_f1': 0.7859587409132387, 'eval_runtime': 127.2861, 'eval_samples_per_second': 99.186, 'eval_steps_per_second': 9.923, 'epoch': 4.0}\n",
      "{'loss': 0.5488, 'grad_norm': 4.975074291229248, 'learning_rate': 0.0001952414275717285, 'epoch': 4.02}\n",
      "{'loss': 0.528, 'grad_norm': 4.00095272064209, 'learning_rate': 0.00018649405178446465, 'epoch': 4.07}\n",
      "{'loss': 0.5371, 'grad_norm': 2.7952828407287598, 'learning_rate': 0.00017774667599720085, 'epoch': 4.11}\n",
      "{'loss': 0.5316, 'grad_norm': 2.629671335220337, 'learning_rate': 0.00016899930020993704, 'epoch': 4.16}\n",
      "{'loss': 0.5672, 'grad_norm': 8.424694061279297, 'learning_rate': 0.00016025192442267318, 'epoch': 4.2}\n",
      "{'loss': 0.5497, 'grad_norm': 2.5696334838867188, 'learning_rate': 0.00015150454863540938, 'epoch': 4.24}\n",
      "{'loss': 0.5524, 'grad_norm': 9.766387939453125, 'learning_rate': 0.00014275717284814558, 'epoch': 4.29}\n",
      "{'loss': 0.5331, 'grad_norm': 3.133939743041992, 'learning_rate': 0.00013400979706088174, 'epoch': 4.33}\n",
      "{'loss': 0.5397, 'grad_norm': 2.977886438369751, 'learning_rate': 0.0001252624212736179, 'epoch': 4.37}\n",
      "{'loss': 0.5335, 'grad_norm': 9.363992691040039, 'learning_rate': 0.0001165150454863541, 'epoch': 4.42}\n",
      "{'loss': 0.5181, 'grad_norm': 3.928636312484741, 'learning_rate': 0.00010776766969909026, 'epoch': 4.46}\n",
      "{'loss': 0.5407, 'grad_norm': 2.374457359313965, 'learning_rate': 9.902029391182646e-05, 'epoch': 4.5}\n",
      "{'loss': 0.5405, 'grad_norm': 1.5735485553741455, 'learning_rate': 9.027291812456263e-05, 'epoch': 4.55}\n",
      "{'loss': 0.518, 'grad_norm': 5.7741193771362305, 'learning_rate': 8.152554233729881e-05, 'epoch': 4.59}\n",
      "{'loss': 0.5329, 'grad_norm': 3.802262783050537, 'learning_rate': 7.2778166550035e-05, 'epoch': 4.64}\n",
      "{'loss': 0.5048, 'grad_norm': 8.262712478637695, 'learning_rate': 6.403079076277118e-05, 'epoch': 4.68}\n",
      "{'loss': 0.5645, 'grad_norm': 4.350508689880371, 'learning_rate': 5.5283414975507345e-05, 'epoch': 4.72}\n",
      "{'loss': 0.5336, 'grad_norm': 3.6556317806243896, 'learning_rate': 4.653603918824353e-05, 'epoch': 4.77}\n",
      "{'loss': 0.539, 'grad_norm': 2.920182228088379, 'learning_rate': 3.778866340097971e-05, 'epoch': 4.81}\n",
      "{'loss': 0.5474, 'grad_norm': 2.1114158630371094, 'learning_rate': 2.9041287613715886e-05, 'epoch': 4.85}\n",
      "{'loss': 0.5216, 'grad_norm': 9.479743003845215, 'learning_rate': 2.0293911826452065e-05, 'epoch': 4.9}\n",
      "{'loss': 0.513, 'grad_norm': 1.880647897720337, 'learning_rate': 1.1546536039188244e-05, 'epoch': 4.94}\n",
      "{'loss': 0.5254, 'grad_norm': 2.4487736225128174, 'learning_rate': 2.7991602519244227e-06, 'epoch': 4.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb3680f8ae64c55a972fa49ec120d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5454385280609131, 'eval_accuracy': 0.7908910891089109, 'eval_precision': 0.7984121773063945, 'eval_recall': 0.7908910891089109, 'eval_f1': 0.7928343452975406, 'eval_runtime': 132.377, 'eval_samples_per_second': 95.372, 'eval_steps_per_second': 9.541, 'epoch': 5.0}\n",
      "{'train_runtime': 17045.3811, 'train_samples_per_second': 33.533, 'train_steps_per_second': 3.353, 'train_loss': 0.6242901519764713, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=57160, training_loss=0.6242901519764713, metrics={'train_runtime': 17045.3811, 'train_samples_per_second': 33.533, 'train_steps_per_second': 3.353, 'total_flos': 7.682690758385664e+16, 'train_loss': 0.6242901519764713, 'epoch': 5.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0jn1iHMyJNtM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Trained model predictions\n",
      "It was good. - LEFT\n",
      "Not a fan, don't recommended - CENTER\n",
      "Better than the first one. - LEFT\n",
      "Women have the right to choose and abortion should be allowed. - LEFT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = model.to(device)\n",
    "print(\"Trained model predictions\")\n",
    "\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    logits = model(inputs).logits\n",
    "\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    print(f\"{text} - {id2label[predictions.item()]}\")\n",
    "\n",
    "\n",
    "# INITIAL CODE\n",
    "# model.to('cuda')\n",
    "# print('Trained model predictions')\n",
    "# for text in text_list:\n",
    "#   inputs = tokenizer.encode(text, return_tensors='pt').to('cuda')\n",
    "\n",
    "#   logits = model(inputs).logits\n",
    "#   predictions = torch.max(logits,1).indices\n",
    "\n",
    "#   print(f'{text} - {id2label[predictions.tolist()[0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQ9UjA-nLGzS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files saved\n"
     ]
    }
   ],
   "source": [
    "output_model_file = \"pytorch_distilbert_imbd.bin\"\n",
    "output_vocab_file = \"vocab_distilbert_imbd.bin\"\n",
    "\n",
    "# Save model\n",
    "model_to_save = model\n",
    "torch.save(model_to_save, output_model_file)\n",
    "\n",
    "# Save tokenizer vocabulary in the current directory\n",
    "tokenizer.save_vocabulary(\".\")  # Current directory\n",
    "\n",
    "# Save model state dictionary\n",
    "torch.save(model.state_dict(), \"LORA_distilBERT_LEAD.pth\")\n",
    "\n",
    "print(\"All files saved\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
