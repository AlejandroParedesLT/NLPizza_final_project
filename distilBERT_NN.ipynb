{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2sMmlrTBL6W"
   },
   "source": [
    "# Alejandro Paredes, Parameter tuning of distilBERT\n",
    "\n",
    "https://arunm8489.medium.com/understanding-distil-bert-in-depth-5f2ca92cf1ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4pNpc6KmBRY4",
    "outputId": "a02a3279-1b48-48b8-da39-8402311f6642"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwAV24NJ-ZSj",
    "outputId": "ca33db64-8fcd-4613-f9d9-dba631f74faa"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers datasets peft evaluate datasets contractions tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "C2gg1Syx-s44",
    "outputId": "eb798168-37c2-45d0-e18b-69982ec24a05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DistilBertModel,\n",
    "    DistilBertTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "import contractions\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import preprocessor as p\n",
    "\n",
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yrj-hSULAi_a",
    "outputId": "c2c054b0-7912-4250-f086-488b4b093400"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning'],\n",
       "        num_rows: 117374\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning'],\n",
       "        num_rows: 29344\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load all CSV files in the ./data directory\n",
    "#data_files = \"./data/*.csv\"\n",
    "\n",
    "# Load and combine the datasets\n",
    "dataset = load_dataset(\"csv\", data_files=\"./data/2017_1.csv\")#data_files)\n",
    "\n",
    "# Filter and split the dataset\n",
    "df  = dataset['train'].filter(\n",
    "    lambda example: example['headline'] is not None and example['headline'].strip() != ''\n",
    ").train_test_split(test_size=0.2)\n",
    "\n",
    "# Display the resulting dataset\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_8Wqw02VBL6f"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = 'distilbert-base-uncased'\n",
    "\n",
    "#Define label maps\n",
    "id2label = {0:\"UNDEFINED\" ,1:\"LEFT\",2:\"RIGHT\",3:\"CENTER\"}\n",
    "label2id = {\"UNDEFINED\": 0, \"LEFT\": 1, \"RIGHT\": 2, \"CENTER\": 3}\n",
    "\n",
    "tokenizer =  DistilBertTokenizer.from_pretrained(model_checkpoint, add_prefix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "r1fchlLlBL6g"
   },
   "outputs": [],
   "source": [
    "#lemmatization and removing stopwords\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "#stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.SMILEY)\n",
    "\n",
    "def preprocess(text):\n",
    "    def is_english_word(word):\n",
    "        \"\"\"Function to filter out non-English words.\"\"\"\n",
    "        return bool(re.match(r'^[a-zA-Z]+$', word))\n",
    "    text = text.lower()\n",
    "    text = contractions.fix(text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    text = p.clean(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vKd0MpK9BFPv",
    "outputId": "82415701-c8f9-4104-a2e0-91c50eee79a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  State Department denies release of Tillerson communication on Russia \n",
      "\n",
      "Tokenized Text:  ['state', 'department', 'denies', 'release', 'of', 'till', '##erson', 'communication', 'on', 'russia'] \n",
      "\n",
      "Token IDs:  [2110, 2533, 23439, 2713, 1997, 6229, 18617, 4807, 2006, 3607]\n",
      "Original Text:  The Guardian view on air pollution: playing politics with the nation’s health \n",
      "\n",
      "Tokenized Text:  ['the', 'guardian', 'view', 'on', 'air', 'pollution', ':', 'playing', 'politics', 'with', 'the', 'nation', 's', 'health'] \n",
      "\n",
      "Token IDs:  [1996, 6697, 3193, 2006, 2250, 10796, 1024, 2652, 4331, 2007, 1996, 3842, 1521, 1055, 2740]\n",
      "Original Text:  Channel 4 is overdue an escape from the London media bubble \n",
      "\n",
      "Tokenized Text:  ['channel', '4', 'is', 'over', '##due', 'an', 'escape', 'from', 'the', 'london', 'media', 'bubble'] \n",
      "\n",
      "Token IDs:  [3149, 1018, 2003, 2058, 20041, 2019, 4019, 2013, 1996, 2414, 2865, 11957]\n",
      "Original Text:  Hawaii bill would bar licenses for some foreign fishermen \n",
      "\n",
      "Tokenized Text:  ['hawaii', 'bill', 'would', 'bar', 'licenses', 'for', 'some', 'foreign', 'fishermen'] \n",
      "\n",
      "Token IDs:  [7359, 3021, 2052, 3347, 15943, 2005, 2070, 3097, 16532]\n",
      "Original Text:  Trump's handling of Mike Flynn exposes his incompetence on national security \n",
      "\n",
      "Tokenized Text:  ['trump', \"'\", 's', 'handling', 'of', 'mike', 'flynn', 'expose', '##s', 'his', 'inc', '##omp', '##ete', '##nce', 'on', 'national', 'security'] \n",
      "\n",
      "Token IDs:  [8398, 1005, 1055, 8304, 1997, 3505, 13259, 14451, 2015, 2010, 4297, 25377, 12870, 5897, 2006, 2120, 3036]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('Original Text: ', df['train']['headline'][i], '\\n')\n",
    "    print('Tokenized Text: ', tokenizer.tokenize(preprocess(df['train']['headline'][i])), '\\n')\n",
    "    print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(df['train']['headline'][i])))\n",
    "\n",
    "#for i in range(2):\n",
    "    #print('Original Text: ', df['train']['body'][i], '\\n')\n",
    "    #print('Tokenized Text: ', tokenizer.tokenize(preprocess(df['train']['body'][i])), '\\n')\n",
    "    #print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(df['train']['body'][i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B99-PUpHBL6i",
    "outputId": "2236512c-c887-4f9c-bb2d-3bca43abec77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline Lengths\n",
      "min 1\n",
      "max 40\n",
      "records with more thatn 300 words: 0\n",
      "Body Lengths\n",
      "min 15\n",
      "max 17700\n",
      "records with more thatn 300 words: 77643\n"
     ]
    }
   ],
   "source": [
    "texts = df['train']['headline']\n",
    "\n",
    "# Handle None or missing values by filtering out None entries\n",
    "text_lengths = [len(text.split(' ')) if text is not None else 0 for text in texts]\n",
    "print(\"Headline Lengths\")\n",
    "print(\"min\", min(text_lengths))\n",
    "print(\"max\", max(text_lengths))\n",
    "\n",
    "# Count how many texts have 300 or more words\n",
    "print(\"records with more thatn 300 words:\", sum([1 for length in text_lengths if length >= 300]))\n",
    "\n",
    "# Repeat for the 'body' column\n",
    "texts = df['train']['body']\n",
    "\n",
    "# Handle None or missing values by filtering out None entries\n",
    "text_lengths = [len(text.split()) if text is not None else 0 for text in texts]\n",
    "print(\"Body Lengths\")\n",
    "print(\"min\", min(text_lengths))\n",
    "print(\"max\",max(text_lengths))\n",
    "\n",
    "# Count how many texts have 300 or more words\n",
    "print(\"records with more thatn 300 words:\", sum([1 for length in text_lengths if length >= 300]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWWgLAscBL6j"
   },
   "source": [
    "# **Creating a custom model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "k0vbHLyjBL6j"
   },
   "outputs": [],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model.\n",
    "\n",
    "class DistillBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistillBERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(model_checkpoint, num_labels=4)\n",
    "\n",
    "        # Freeze DistilBERT parameters\n",
    "        for param in self.l1.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.fc1 = torch.nn.Linear(768, 1024)  # Input dimension is 768 for BERT\n",
    "        #self.fc2 = torch.nn.Linear(1024, 512)\n",
    "        self.classifier = torch.nn.Linear(1024, 4)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        pooler = self.fc1(pooler)\n",
    "        pooler = self.relu(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        #pooler = self.fc2(pooler)\n",
    "        #pooler = self.relu(pooler)\n",
    "        #pooler = self.dropout(pooler)\n",
    "        #pooler = self.fc3(pooler)\n",
    "        #pooler = self.softmax(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data imbalance\n",
    "\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import pandas as pd\n",
    "df_expection = pd.read_csv('./data/2017_1.csv')\n",
    "\n",
    "df_expection.political_leaning.value_counts()\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(df_expection['political_leaning']), y=df_expection['political_leaning'])\n",
    "class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "#class_weights_dict = dict(zip(np.unique(df_expection['political_leaning']), class_weights))\n",
    "# Convert class weights into a tensor\n",
    "#weights = torch.tensor([class_weights_dict[label] for label in df_expection['political_leaning']])\n",
    "#sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MjBjQXj4BL6j",
    "outputId": "5e40bd38-b4d1-4dc0-e6fc-5527e3faea3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistillBERTClass(\n",
       "  (l1): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (fc1): Linear(in_features=768, out_features=1024, bias=True)\n",
       "  (classifier): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 10\n",
    "VALID_BATCH_SIZE = 10\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-04\n",
    "\n",
    "model = DistillBERTClass()\n",
    "model.to(device)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss(weight=class_weights.to(device),reduction='mean')\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.4)\n",
    "\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUWKDy2QBL6k",
    "outputId": "0e2e9bed-41a3-4608-b03c-36896aaf047b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1.embeddings.word_embeddings.weight: requires_grad=False\n",
      "l1.embeddings.position_embeddings.weight: requires_grad=False\n",
      "l1.embeddings.LayerNorm.weight: requires_grad=False\n",
      "l1.embeddings.LayerNorm.bias: requires_grad=False\n",
      "l1.transformer.layer.0.attention.q_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.0.attention.q_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.0.attention.k_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.0.attention.k_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.0.attention.v_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.0.attention.v_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.0.attention.out_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.0.attention.out_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.0.sa_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.0.sa_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.0.ffn.lin1.weight: requires_grad=False\n",
      "l1.transformer.layer.0.ffn.lin1.bias: requires_grad=False\n",
      "l1.transformer.layer.0.ffn.lin2.weight: requires_grad=False\n",
      "l1.transformer.layer.0.ffn.lin2.bias: requires_grad=False\n",
      "l1.transformer.layer.0.output_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.0.output_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.1.attention.q_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.1.attention.q_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.1.attention.k_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.1.attention.k_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.1.attention.v_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.1.attention.v_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.1.attention.out_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.1.attention.out_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.1.sa_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.1.sa_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.1.ffn.lin1.weight: requires_grad=False\n",
      "l1.transformer.layer.1.ffn.lin1.bias: requires_grad=False\n",
      "l1.transformer.layer.1.ffn.lin2.weight: requires_grad=False\n",
      "l1.transformer.layer.1.ffn.lin2.bias: requires_grad=False\n",
      "l1.transformer.layer.1.output_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.1.output_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.2.attention.q_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.2.attention.q_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.2.attention.k_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.2.attention.k_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.2.attention.v_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.2.attention.v_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.2.attention.out_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.2.attention.out_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.2.sa_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.2.sa_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.2.ffn.lin1.weight: requires_grad=False\n",
      "l1.transformer.layer.2.ffn.lin1.bias: requires_grad=False\n",
      "l1.transformer.layer.2.ffn.lin2.weight: requires_grad=False\n",
      "l1.transformer.layer.2.ffn.lin2.bias: requires_grad=False\n",
      "l1.transformer.layer.2.output_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.2.output_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.3.attention.q_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.3.attention.q_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.3.attention.k_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.3.attention.k_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.3.attention.v_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.3.attention.v_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.3.attention.out_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.3.attention.out_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.3.sa_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.3.sa_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.3.ffn.lin1.weight: requires_grad=False\n",
      "l1.transformer.layer.3.ffn.lin1.bias: requires_grad=False\n",
      "l1.transformer.layer.3.ffn.lin2.weight: requires_grad=False\n",
      "l1.transformer.layer.3.ffn.lin2.bias: requires_grad=False\n",
      "l1.transformer.layer.3.output_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.3.output_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.4.attention.q_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.4.attention.q_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.4.attention.k_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.4.attention.k_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.4.attention.v_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.4.attention.v_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.4.attention.out_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.4.attention.out_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.4.sa_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.4.sa_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.4.ffn.lin1.weight: requires_grad=False\n",
      "l1.transformer.layer.4.ffn.lin1.bias: requires_grad=False\n",
      "l1.transformer.layer.4.ffn.lin2.weight: requires_grad=False\n",
      "l1.transformer.layer.4.ffn.lin2.bias: requires_grad=False\n",
      "l1.transformer.layer.4.output_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.4.output_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.5.attention.q_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.5.attention.q_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.5.attention.k_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.5.attention.k_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.5.attention.v_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.5.attention.v_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.5.attention.out_lin.weight: requires_grad=False\n",
      "l1.transformer.layer.5.attention.out_lin.bias: requires_grad=False\n",
      "l1.transformer.layer.5.sa_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.5.sa_layer_norm.bias: requires_grad=False\n",
      "l1.transformer.layer.5.ffn.lin1.weight: requires_grad=False\n",
      "l1.transformer.layer.5.ffn.lin1.bias: requires_grad=False\n",
      "l1.transformer.layer.5.ffn.lin2.weight: requires_grad=False\n",
      "l1.transformer.layer.5.ffn.lin2.bias: requires_grad=False\n",
      "l1.transformer.layer.5.output_layer_norm.weight: requires_grad=False\n",
      "l1.transformer.layer.5.output_layer_norm.bias: requires_grad=False\n",
      "pre_classifier.weight: requires_grad=True\n",
      "pre_classifier.bias: requires_grad=True\n",
      "fc1.weight: requires_grad=True\n",
      "fc1.bias: requires_grad=True\n",
      "classifier.weight: requires_grad=True\n",
      "classifier.bias: requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YmGXgdNQCb7e"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "  tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "  model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZgXdBTYUDLz6"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    #text = examples[\"body\"]\n",
    "    text = examples[\"body\"]\n",
    "    labels = examples[\"political_leaning\"]\n",
    "\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,#[preprocess(t) for t in text] ,\n",
    "        return_tensors = \"np\",\n",
    "        #padding = True,\n",
    "        truncation = True,\n",
    "        max_length = 512\n",
    "        )\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = [label2id[label] for label in labels]\n",
    "    return tokenized_inputs\n",
    "\n",
    "#tokenized_dataset = df.map(tokenize_function, batched=True)\n",
    "#tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Vf28kN8fBL6l"
   },
   "outputs": [],
   "source": [
    "# Define split ratio for validation\n",
    "train_test_split = df[\"train\"].train_test_split(test_size=0.1)  # 10% for validation\n",
    "datasets = DatasetDict({\n",
    "    \"train\": train_test_split[\"train\"],\n",
    "    \"validation\": train_test_split[\"test\"],  # This is your validation set\n",
    "    \"test\": df[\"test\"],       # Keep the original test set\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_4hEof0NBL6l"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import contractions\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    \"\"\" Preprocess the text to clean it for tokenization \"\"\"\n",
    "    def is_english_word(word):\n",
    "        \"\"\"Function to filter out non-English words.\"\"\"\n",
    "        return bool(re.match(r'^[a-zA-Z]+$', word))\n",
    "\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = contractions.fix(text)  # Expand contractions (e.g., \"don't\" -> \"do not\")\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII characters\n",
    "    text = p.clean(text)  # Clean text using the clean-text library\n",
    "    return text\n",
    "\n",
    "class Triage(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_length):\n",
    "        self.texts = dataset['body']  # Assuming 'text' column contains the raw text\n",
    "        self.labels = dataset['political_leaning']\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.document_id = dataset['id']\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get raw text and label for the current index\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        tokenizer.truncation_side = \"left\"\n",
    "        #tokenized_inputs = self.tokenizer(\n",
    "        tokenized_inputs = self.tokenizer.encode_plus(\n",
    "            preprocess(text),\n",
    "            None,\n",
    "            #return_tensors=\"pt\",\n",
    "            #padding=True,\n",
    "            truncation=True,\n",
    "            #max_length=self.max_length\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_max_length=True\n",
    "        )\n",
    "\n",
    "        #encoding = tokenize_function({\"text\": [text], \"labels\": [label]}, self.tokenizer, self.max_length)\n",
    "        input_ids = tokenized_inputs['input_ids']  # Remove the batch dimension\n",
    "        attention_mask = tokenized_inputs['attention_mask']  # Remove the batch dimension\n",
    "\n",
    "        return {\n",
    "            'document_id': self.document_id[index],\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(label2id[self.labels[index]], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mvrU6xHpBL6l"
   },
   "outputs": [],
   "source": [
    "train_dataset = Triage(datasets['train'], tokenizer, max_length=512)\n",
    "val_dataset = Triage(datasets['validation'], tokenizer, max_length=512)\n",
    "test_dataset = Triage(datasets['test'], tokenizer, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "On3GSFT7BL6l"
   },
   "outputs": [],
   "source": [
    "# Training DataLoader\n",
    "training_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Validation DataLoader\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=VALID_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "# Test DataLoader\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=VALID_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iR8md4S6BL6m"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "o4hduUwTGnN5"
   },
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
    "def calculate_accuracy(preds, targets):\n",
    "    n_correct = (preds==targets).sum().item()\n",
    "    return n_correct\n",
    "\n",
    "def train(epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    model.train()\n",
    "    for _,data in tqdm(enumerate(training_loader, 0)):\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "        #token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['labels'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask)#, token_type_ids)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calculate_accuracy(big_idx, targets)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "\n",
    "        if _%500==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step = (n_correct*100)/nb_tr_examples\n",
    "            print(f\"Training Loss per 500 steps: {loss_step}\")\n",
    "            print(f\"Training Accuracy per 500 steps: {accu_step}\")\n",
    "            with open(\"./results/v5/step_results.txt\", \"a\") as file:\n",
    "                file.write(f\"{loss_step}|{accu_step}\\n\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "\n",
    "    return epoch_loss, epoch_accu\n",
    "\n",
    "def valid(model, testing_loader):\n",
    "    model.eval()\n",
    "    n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "            #token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['labels'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask).squeeze()\n",
    "            loss = loss_function(outputs, targets)\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            n_correct += calculate_accuracy(big_idx, targets)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "\n",
    "            if _%5000==0:\n",
    "                loss_step = tr_loss/nb_tr_steps\n",
    "                accu_step = (n_correct*100)/nb_tr_examples\n",
    "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
    "                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
    "\n",
    "    return epoch_loss, epoch_accu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Alert: the model was retrained several times by reloading the previous checkpoint, therefore the printed amount of epochs showed below does not represent the real amount of epochs runned for this model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kupJM6s-BL6m",
    "outputId": "4c9b160c-c896-49ea-ef79-df30aa362096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.202505350112915\n",
      "Training Accuracy per 500 steps: 60.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [02:33,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1149789002127277\n",
      "Training Accuracy per 500 steps: 62.115768463073856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [05:07,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1111683024393095\n",
      "Training Accuracy per 500 steps: 62.26773226773227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [07:50,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1100123498060162\n",
      "Training Accuracy per 500 steps: 62.47834776815456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [10:38,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1080804257497736\n",
      "Training Accuracy per 500 steps: 62.70364817591204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2501it [13:24,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.107815322519445\n",
      "Training Accuracy per 500 steps: 62.74290283886445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [16:07,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.106111496955067\n",
      "Training Accuracy per 500 steps: 63.042319226924356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3501it [18:55,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1062078180738055\n",
      "Training Accuracy per 500 steps: 63.09054555841188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [21:40,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1053066715631625\n",
      "Training Accuracy per 500 steps: 63.18670332416896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4501it [24:24,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1039579770772145\n",
      "Training Accuracy per 500 steps: 63.29704510108865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [27:09,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1043687061509284\n",
      "Training Accuracy per 500 steps: 63.24735052989402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5501it [29:58,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1032640134674965\n",
      "Training Accuracy per 500 steps: 63.384839120159974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [32:47,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.102674295566138\n",
      "Training Accuracy per 500 steps: 63.47108815197467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6501it [35:33,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1019371922447798\n",
      "Training Accuracy per 500 steps: 63.534840793724044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7001it [38:20,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1010513236192\n",
      "Training Accuracy per 500 steps: 63.60377088987288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7501it [41:03,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.100497026067466\n",
      "Training Accuracy per 500 steps: 63.6621783762165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8001it [43:44,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1006019579784645\n",
      "Training Accuracy per 500 steps: 63.61204849393826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8501it [46:20,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.100622934862356\n",
      "Training Accuracy per 500 steps: 63.6513351370427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9001it [49:02,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.100515656187301\n",
      "Training Accuracy per 500 steps: 63.654038440173316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9501it [51:54,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.1001671926057561\n",
      "Training Accuracy per 500 steps: 63.69013788022313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [54:59,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.0995906032737333\n",
      "Training Accuracy per 500 steps: 63.76162383761624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10501it [58:09,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.0988758089042665\n",
      "Training Accuracy per 500 steps: 63.8396343205409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10564it [58:33,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 0: 63.85228520580105\n",
      "Training Loss Epoch: 1.0987412251563111\n",
      "Training Accuracy Epoch: 63.85228520580105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss per 100 steps: 1.095953345298767\n",
      "Validation Accuracy per 100 steps: 70.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1174it [07:08,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss Epoch: 1.1058492241157585\n",
      "Validation Accuracy Epoch: 65.35184869654115\n",
      "Learning rate: 0.0001\n",
      "Saved Best Model!\n",
      "\n",
      "Epoch 2/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 0.9120412468910217\n",
      "Training Accuracy per 500 steps: 80.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [03:02,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.0868044146996534\n",
      "Training Accuracy per 500 steps: 64.57085828343314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [06:13,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.0915305990201014\n",
      "Training Accuracy per 500 steps: 64.27572427572427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [09:17,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.0929060556902876\n",
      "Training Accuracy per 500 steps: 64.01732178547635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [12:23,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.0902194598506296\n",
      "Training Accuracy per 500 steps: 64.3928035982009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2501it [15:08,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.0908607028809036\n",
      "Training Accuracy per 500 steps: 64.43422630947622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [17:50,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.0908367920025155\n",
      "Training Accuracy per 500 steps: 64.50516494501832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3501it [20:33,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.0904757446031916\n",
      "Training Accuracy per 500 steps: 64.55298486146815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [23:17,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.09196160026444\n",
      "Training Accuracy per 500 steps: 64.43139215196202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4501it [25:59,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.092288450912962\n",
      "Training Accuracy per 500 steps: 64.49900022217285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [34:05,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.0915514686254948\n",
      "Training Accuracy per 500 steps: 64.59708058388323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5501it [47:23,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.0903798637011337\n",
      "Training Accuracy per 500 steps: 64.69005635339029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [1:00:53,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 500 steps: 1.0914363359197181\n",
      "Training Accuracy per 500 steps: 64.63589401766372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6497it [1:14:26,  1.65s/it]"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "checkpoint = torch.load(\"./models/local_run_BERT_body_v5/best_model.pt\")\n",
    "print(checkpoint.keys())\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "\n",
    "# Open a file to write the results\n",
    "with open(\"./results/v5/training_results.txt\", \"w\") as file:\n",
    "    # Writing headers to the file\n",
    "    file.write(\"Epoch|Training Loss|Training Accuracy|Validation Loss|Validation Accuracy\\n\")\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        epoch_loss, epoch_accu = train(epoch)\n",
    "        val_loss, val_accuracy = valid(model, val_loader)\n",
    "\n",
    "        # Write the results to the file\n",
    "        file.write(f\"{epoch + 1}|{epoch_loss:.4f}|{epoch_accu:.4f}|{val_loss:.4f}|{val_accuracy:.4f}\\n\")\n",
    "\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(\"Learning rate:\", param_group['lr'])\n",
    "\n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"./models/local_run_BERT_body_v5/best_model.pt\")\n",
    "            print(\"Saved Best Model!\")\n",
    "\n",
    "        if val_accuracy > 91:\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "print(\"Training results saved to 'training_results.txt'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./models/local_run_BERT_body_v5/vocab.txt',)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_vocabulary('./models/local_run_BERT_body_v5/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oETAzaqeBL6m",
    "outputId": "6582bbc4-d9a8-4565-f51e-6a6d9e116941"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALEJANDRO\\AppData\\Local\\Temp\\ipykernel_3564\\737265087.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"./models/local_run_BERT_body_v5/best_model.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistillBERTClass(\n",
       "  (l1): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (fc1): Linear(in_features=768, out_features=1024, bias=True)\n",
       "  (classifier): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./models/local_run_BERT_body_v5/best_model.pt\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxTWh0CZBL6n",
    "outputId": "4a835e32-f0a2-4322-8d33-2ea54f5d937d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on Test Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/2935 [00:00<?, ?it/s]c:\\Users\\ALEJANDRO\\Documents\\7. DUKE\\1. ECE 684 - NLP\\Assignments\\Final Project\\venv_lda_implementation\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Testing:   4%|▍         | 112/2935 [00:35<15:00,  3.14it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# After training and validation, evaluate on the test set\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating on Test Set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m test_accuracy, test_precision, test_recall, test_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 21\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(model, data_loader, device)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;66;03m# Collect predictions and true labels\u001b[39;00m\n\u001b[0;32m     20\u001b[0m         preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m         all_preds\u001b[38;5;241m.\u001b[39mextend(\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     22\u001b[0m         all_labels\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Test function\n",
    "def test_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Testing\"):\n",
    "            # Move batch to GPU/CPU\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            # Collect predictions and true labels\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"weighted\")\n",
    "\n",
    "    print(\"\\nTest Results\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# After training and validation, evaluate on the test set\n",
    "print(\"\\nEvaluating on Test Set\")\n",
    "test_accuracy, test_precision, test_recall, test_f1 = test_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "PcInvd2hBL6n",
    "outputId": "9cb360f6-bc53-4553-d6a5-dac5225290a6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Plot function for metrics\n",
    "def plot_metrics(metrics, metric_names, title):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    bars = ax.bar(metric_names, metrics, color=['skyblue', 'orange', 'green', 'red'])\n",
    "\n",
    "    # Add value annotations on bars\n",
    "    for bar in bars:\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.02,\n",
    "                f\"{bar.get_height():.4f}\", ha='center', fontsize=10)\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_ylabel(\"Score\", fontsize=14)\n",
    "    ax.set_xlabel(\"Metrics\", fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "# After testing, plot the metrics\n",
    "#print(\"\\nEvaluating on Test Set\")\n",
    "#test_accuracy, test_precision, test_recall, test_f1 = test_model(model, test_loader, device)\n",
    "\n",
    "# Metrics and their names\n",
    "metrics = [test_accuracy, test_precision, test_recall, test_f1]\n",
    "metric_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "\n",
    "# Plot the test results\n",
    "plot_metrics(metrics, metric_names, title=\"Test Metrics Overview\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmxsoKs4C1yh"
   },
   "source": [
    "# **Metrics by class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on Test Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/2935 [00:00<?, ?it/s]c:\\Users\\ALEJANDRO\\Documents\\7. DUKE\\1. ECE 684 - NLP\\Assignments\\Final Project\\venv_lda_implementation\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Testing: 100%|██████████| 2935/2935 [15:40<00:00,  3.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions.csv\n",
      "\n",
      "Test Results\n",
      "------------------------------\n",
      "Overall Accuracy: 0.6585\n",
      "\n",
      "Class: UNDEFINED\n",
      "  Accuracy: 0.7089\n",
      "  Precision: 0.6051\n",
      "  Recall: 0.7089\n",
      "  F1-Score: 0.6529\n",
      "\n",
      "Class: LEFT\n",
      "  Accuracy: 0.5448\n",
      "  Precision: 0.7891\n",
      "  Recall: 0.5448\n",
      "  F1-Score: 0.6446\n",
      "\n",
      "Class: RIGHT\n",
      "  Accuracy: 0.4364\n",
      "  Precision: 0.7098\n",
      "  Recall: 0.4364\n",
      "  F1-Score: 0.5405\n",
      "\n",
      "Class: CENTER\n",
      "  Accuracy: 0.7981\n",
      "  Precision: 0.6275\n",
      "  Recall: 0.7981\n",
      "  F1-Score: 0.7026\n",
      "\n",
      "Test Results from CSV\n",
      "Overall Accuracy: 0.6193\n",
      "\n",
      "Class: UNDEFINED\n",
      "  Precision: 0.6498\n",
      "  Recall: 0.5801\n",
      "  F1-Score: 0.6130\n",
      "\n",
      "Class: LEFT\n",
      "  Precision: 0.6407\n",
      "  Recall: 0.6846\n",
      "  F1-Score: 0.6619\n",
      "\n",
      "Class: RIGHT\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1-Score: 0.0000\n",
      "\n",
      "Class: CENTER\n",
      "  Precision: 0.5880\n",
      "  Recall: 0.8185\n",
      "  F1-Score: 0.6844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ALEJANDRO\\Documents\\7. DUKE\\1. ECE 684 - NLP\\Assignments\\Final Project\\venv_lda_implementation\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np  # Add numpy import for array operations\n",
    "\n",
    "def test_model_and_store_predictions(model, data_loader, device, id2label, output_csv=\"predictions.csv\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Testing\"):\n",
    "            # Move batch to GPU/CPU\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            document_id = batch[\"document_id\"]\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            # Collect predictions and true labels\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_ids.extend(document_id.cpu().numpy())  # Save the unique identifier for each record\n",
    "\n",
    "    # Create DataFrame to store predictions along with the actual data\n",
    "    predictions_df = pd.DataFrame({\n",
    "        \"document_id\": all_ids,\n",
    "        \"True_Label\": all_labels,\n",
    "        \"Pred_Label\": all_preds\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    predictions_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Predictions saved to {output_csv}\")\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    # Calculate per-class metrics\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(all_labels, all_preds, average=None)\n",
    "\n",
    "    # Per-class accuracy\n",
    "    per_class_accuracy = {}\n",
    "    for class_idx in range(len(id2label)):\n",
    "        # True positives for this class\n",
    "        true_positive = np.sum((np.array(all_preds) == class_idx) & (np.array(all_labels) == class_idx))\n",
    "        # Total instances of this class in the dataset\n",
    "        total_class_instances = np.sum(np.array(all_labels) == class_idx)\n",
    "        per_class_accuracy[id2label[class_idx]] = true_positive / total_class_instances if total_class_instances > 0 else 0.0\n",
    "\n",
    "    # Prepare and print results\n",
    "    print(\"\\nTest Results\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Print metrics for each class\n",
    "    class_metrics = {}\n",
    "    for idx, label in id2label.items():\n",
    "        class_metrics[label] = {\n",
    "            \"Accuracy\": per_class_accuracy[label],\n",
    "            \"Precision\": precision[idx],\n",
    "            \"Recall\": recall[idx],\n",
    "            \"F1-Score\": f1[idx],\n",
    "        }\n",
    "        print(f\"\\nClass: {label}\")\n",
    "        print(f\"  Accuracy: {per_class_accuracy[label]:.4f}\")\n",
    "        print(f\"  Precision: {precision[idx]:.4f}\")\n",
    "        print(f\"  Recall: {recall[idx]:.4f}\")\n",
    "        print(f\"  F1-Score: {f1[idx]:.4f}\")\n",
    "\n",
    "    return accuracy, class_metrics\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Call the test function and store the predictions\n",
    "print(\"\\nEvaluating on Test Set\")\n",
    "test_accuracy, test_class_metrics = test_model_and_store_predictions(model, test_loader, device, id2label)\n",
    "\n",
    "# After saving predictions to CSV, you can use pandas to compute metrics or analyze the data\n",
    "# Example: Loading the CSV and computing overall metrics\n",
    "predictions_df = pd.read_csv(\"./results/predictions.csv\")\n",
    "accuracy = accuracy_score(predictions_df[\"True_Label\"], predictions_df[\"Pred_Label\"])\n",
    "precision, recall, f1, support = precision_recall_fscore_support(predictions_df[\"True_Label\"], predictions_df[\"Pred_Label\"], average=None)\n",
    "\n",
    "# Print metrics from CSV\n",
    "print(\"\\nTest Results from CSV\")\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "for idx, label in id2label.items():\n",
    "    print(f\"\\nClass: {label}\")\n",
    "    print(f\"  Precision: {precision[idx]:.4f}\")\n",
    "    print(f\"  Recall: {recall[idx]:.4f}\")\n",
    "    print(f\"  F1-Score: {f1[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    True_Label  Pred_Label  Count\n",
      "0          0.0           0   5630\n",
      "5          1.0           1   4617\n",
      "10         2.0           2   1497\n",
      "15         3.0           3   7580\n"
     ]
    }
   ],
   "source": [
    "preds = pd.read_csv(\"predictions.csv\")\n",
    "preds.groupby(\"True_Label\").count()\n",
    "\n",
    "# Group by True_Label and Pred_Label to count occurrences of each combination\n",
    "group_counts = preds.groupby(['True_Label', 'Pred_Label']).size().reset_index(name='Count')\n",
    "\n",
    "# Print the counts of matching labels\n",
    "matching_counts = group_counts[group_counts['True_Label'] == group_counts['Pred_Label']]\n",
    "print(matching_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>True_Label</th>\n",
       "      <th>Pred_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4317187</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4359799</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4314201</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4480303</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4339803</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>4338758</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>4318145</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>4305016</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>4325641</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>4361067</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      document_id  True_Label  Pred_Label\n",
       "0         4317187         2.0           2\n",
       "38        4359799         2.0           2\n",
       "49        4314201         2.0           2\n",
       "56        4480303         2.0           2\n",
       "64        4339803         2.0           2\n",
       "...           ...         ...         ...\n",
       "1455      4338758         2.0           2\n",
       "1465      4318145         2.0           2\n",
       "1472      4305016         2.0           2\n",
       "1504      4325641         2.0           2\n",
       "1516      4361067         2.0           2\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[(preds['True_Label']==preds['Pred_Label']) & (preds['True_Label']==2)].head(100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv_lda_implementation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
