{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT with LoRA for analysis on political leaning of news; SUMMARY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwAV24NJ-ZSj",
    "outputId": "f707f622-fcd8-4645-fc3f-6beaef291c8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/miniconda3/lib/python3.12/site-packages (4.46.3)\n",
      "Requirement already satisfied: datasets in /opt/miniconda3/lib/python3.12/site-packages (3.1.0)\n",
      "Requirement already satisfied: peft in /opt/miniconda3/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: evaluate in /opt/miniconda3/lib/python3.12/site-packages (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ilseoplee/.local/lib/python3.12/site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/miniconda3/lib/python3.12/site-packages (from datasets) (3.11.0)\n",
      "Requirement already satisfied: psutil in /opt/miniconda3/lib/python3.12/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/miniconda3/lib/python3.12/site-packages (from peft) (2.5.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/miniconda3/lib/python3.12/site-packages (from peft) (1.1.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (75.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets peft evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "C2gg1Syx-s44"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KfUh_vrS_hbR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "\n",
    "# Define label maps\n",
    "id2label = {0: \"UNDEFINED\", 1: \"LEFT\", 2: \"RIGHT\", 3: \"CENTER\"}\n",
    "label2id = {\"UNDEFINED\": 0, \"LEFT\": 1, \"RIGHT\": 2, \"CENTER\": 3}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=4, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Yrj-hSULAi_a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning', 'summary'],\n",
       "        num_rows: 19328\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "df = load_dataset(\"csv\", data_files=\"/Users/ilseoplee/NLPizza_final_project/Filing/LORA_Summary/training_data_body_summary_19K.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_testvalid =\n",
    "df = df[\"train\"].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vKd0MpK9BFPv"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ERySJZcQBp9_"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    text = examples[\"summary\"]\n",
    "    labels = examples[\"political_leaning\"]\n",
    "\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text, return_tensors=\"np\", padding=True, truncation=True, max_length=512\n",
    "    )\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = [label2id[label] for label in labels]\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YmGXgdNQCb7e"
   },
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZgXdBTYUDLz6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2933ea43cb484be68b2c49a791ef1eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17395 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7768aa518634c0887d304475fae2fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1933 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 17395\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'date_publish', 'outlet', 'headline', 'lead', 'body', 'authors', 'domain', 'url', 'political_leaning', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1933\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = df.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IjSOWH6wDNHw"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KJvaBgtkD963"
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6nP1LQquEmt2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model\n",
      "It was good. - UNDEFINED\n",
      "Not a fan, don't recommended - UNDEFINED\n",
      "Better than the first one. - CENTER\n",
      "Women have the right to choose and abortion should be allowed. - UNDEFINED\n"
     ]
    }
   ],
   "source": [
    "text_list = [\n",
    "    \"It was good.\",\n",
    "    \"Not a fan, don't recommended\",\n",
    "    \"Better than the first one.\",\n",
    "    \"Women have the right to choose and abortion should be allowed.\",\n",
    "]\n",
    "\n",
    "import torch\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Untrained model\")\n",
    "for text in text_list:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(\n",
    "        device\n",
    "    )  # Move inputs to the correct device\n",
    "    logits = model(**inputs).logits  # Forward pass\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    print(f\"{text} - {id2label[predictions.item()]}\")\n",
    "\n",
    "# print(\"Untrained model\")\n",
    "# for text in text_list:\n",
    "#   inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "#   logits = model(inputs).logits\n",
    "#   predictions = torch.argmax(logits)\n",
    "#   print(f'{text} - {id2label[predictions.tolist()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "8xiaVnUaF1Yf"
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\", r=12, lora_alpha=32, lora_dropout=0.01, target_modules=[\"q_lin\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "3ORBVjXnGx19"
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 10\n",
    "num_epochs = 5\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"\" + model_checkpoint + \"lora-txt\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):  #Training\n",
    "    \"\"\"\n",
    "    Computes accuracy, precision, recall, and F1 score.\n",
    "    eval_pred: A tuple of (predictions, labels) provided by the Trainer.\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    # Convert predictions to the predicted class indices (argmax for softmax outputs)\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions, average='weighted')  # Weighted for class imbalance\n",
    "    recall = recall_score(labels, predictions, average='weighted')\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "hmS4TS65IDDV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/gkxw33gj58n2ptpf02t8_ncr0000gn/T/ipykernel_97031/552906714.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "gfzk-YnMJL0V"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0683ca85bc774debbaba92d1eb5c0f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1493, 'grad_norm': 2.0976951122283936, 'learning_rate': 0.0009425287356321838, 'epoch': 0.29}\n",
      "{'loss': 1.0608, 'grad_norm': 2.5578582286834717, 'learning_rate': 0.0008850574712643679, 'epoch': 0.57}\n",
      "{'loss': 1.0549, 'grad_norm': 1.7384960651397705, 'learning_rate': 0.0008275862068965517, 'epoch': 0.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0d1d2648db4df9b9871710736bb31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0149575471878052, 'eval_accuracy': 0.5576823590274185, 'eval_precision': 0.5576650132188341, 'eval_recall': 0.5576823590274185, 'eval_f1': 0.5432822625324656, 'eval_runtime': 11.4717, 'eval_samples_per_second': 168.501, 'eval_steps_per_second': 16.911, 'epoch': 1.0}\n",
      "{'loss': 1.0053, 'grad_norm': 2.834160327911377, 'learning_rate': 0.0007701149425287356, 'epoch': 1.15}\n",
      "{'loss': 0.989, 'grad_norm': 2.729121446609497, 'learning_rate': 0.0007126436781609196, 'epoch': 1.44}\n",
      "{'loss': 0.981, 'grad_norm': 2.7624571323394775, 'learning_rate': 0.0006551724137931034, 'epoch': 1.72}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd137942b444881a525f4c10cfc7233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9866294860839844, 'eval_accuracy': 0.5804449042938438, 'eval_precision': 0.5765379576458176, 'eval_recall': 0.5804449042938438, 'eval_f1': 0.574008690898699, 'eval_runtime': 11.035, 'eval_samples_per_second': 175.169, 'eval_steps_per_second': 17.58, 'epoch': 2.0}\n",
      "{'loss': 0.9656, 'grad_norm': 2.1639926433563232, 'learning_rate': 0.0005977011494252874, 'epoch': 2.01}\n",
      "{'loss': 0.913, 'grad_norm': 2.016406536102295, 'learning_rate': 0.0005402298850574712, 'epoch': 2.3}\n",
      "{'loss': 0.9056, 'grad_norm': 2.2516777515411377, 'learning_rate': 0.0004827586206896552, 'epoch': 2.59}\n",
      "{'loss': 0.9015, 'grad_norm': 2.457991361618042, 'learning_rate': 0.00042528735632183906, 'epoch': 2.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64fdf47e2454ae7af95493806fb2be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9759300947189331, 'eval_accuracy': 0.5840662183135024, 'eval_precision': 0.5944183217431899, 'eval_recall': 0.5840662183135024, 'eval_f1': 0.5783113770444677, 'eval_runtime': 10.7888, 'eval_samples_per_second': 179.167, 'eval_steps_per_second': 17.982, 'epoch': 3.0}\n",
      "{'loss': 0.8622, 'grad_norm': 4.048056125640869, 'learning_rate': 0.000367816091954023, 'epoch': 3.16}\n",
      "{'loss': 0.8299, 'grad_norm': 2.778053045272827, 'learning_rate': 0.0003103448275862069, 'epoch': 3.45}\n",
      "{'loss': 0.8419, 'grad_norm': 3.2340686321258545, 'learning_rate': 0.00025287356321839085, 'epoch': 3.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce0c3676756403d8d459effd39aa632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9835162162780762, 'eval_accuracy': 0.5959648215209519, 'eval_precision': 0.5919171076115526, 'eval_recall': 0.5959648215209519, 'eval_f1': 0.5889405909288957, 'eval_runtime': 11.6488, 'eval_samples_per_second': 165.94, 'eval_steps_per_second': 16.654, 'epoch': 4.0}\n",
      "{'loss': 0.8267, 'grad_norm': 3.102609872817993, 'learning_rate': 0.00019540229885057472, 'epoch': 4.02}\n",
      "{'loss': 0.7574, 'grad_norm': 2.841707706451416, 'learning_rate': 0.00013793103448275863, 'epoch': 4.31}\n",
      "{'loss': 0.7639, 'grad_norm': 3.844043493270874, 'learning_rate': 8.045977011494253e-05, 'epoch': 4.6}\n",
      "{'loss': 0.7647, 'grad_norm': 2.497410535812378, 'learning_rate': 2.2988505747126437e-05, 'epoch': 4.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b11ed2925e341fb899ba89c6960bd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0004345178604126, 'eval_accuracy': 0.5923435075012933, 'eval_precision': 0.5883787820307593, 'eval_recall': 0.5923435075012933, 'eval_f1': 0.587215559250738, 'eval_runtime': 10.9506, 'eval_samples_per_second': 176.52, 'eval_steps_per_second': 17.716, 'epoch': 5.0}\n",
      "{'train_runtime': 1117.7161, 'train_samples_per_second': 77.815, 'train_steps_per_second': 7.784, 'train_loss': 0.91250649813948, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8700, training_loss=0.91250649813948, metrics={'train_runtime': 1117.7161, 'train_samples_per_second': 77.815, 'train_steps_per_second': 7.784, 'total_flos': 2439377683482480.0, 'train_loss': 0.91250649813948, 'epoch': 5.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0jn1iHMyJNtM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Trained model predictions\n",
      "It was good. - LEFT\n",
      "Not a fan, don't recommended - LEFT\n",
      "Better than the first one. - LEFT\n",
      "Women have the right to choose and abortion should be allowed. - LEFT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = model.to(device)\n",
    "print(\"Trained model predictions\")\n",
    "\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    logits = model(inputs).logits\n",
    "\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    print(f\"{text} - {id2label[predictions.item()]}\")\n",
    "\n",
    "\n",
    "# INITIAL CODE\n",
    "# model.to('cuda')\n",
    "# print('Trained model predictions')\n",
    "# for text in text_list:\n",
    "#   inputs = tokenizer.encode(text, return_tensors='pt').to('cuda')\n",
    "\n",
    "#   logits = model(inputs).logits\n",
    "#   predictions = torch.max(logits,1).indices\n",
    "\n",
    "#   print(f'{text} - {id2label[predictions.tolist()[0]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "OQ9UjA-nLGzS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files saved\n"
     ]
    }
   ],
   "source": [
    "output_model_file = \"pytorch_distilbert_imbd.bin\"\n",
    "output_vocab_file = \"vocab_distilbert_imbd.bin\"\n",
    "\n",
    "# Save model\n",
    "model_to_save = model\n",
    "torch.save(model_to_save, output_model_file)\n",
    "\n",
    "# Save tokenizer vocabulary in the current directory\n",
    "tokenizer.save_vocabulary(\".\")  # Current directory\n",
    "\n",
    "# Save model state dictionary\n",
    "torch.save(model.state_dict(), \"LORA_distilBERT_SUMMARY_2017_2_T5_Base.pth\")\n",
    "\n",
    "print(\"All files saved\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
